{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "express-anime",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:25:56.445879Z",
     "iopub.status.busy": "2021-05-21T13:25:56.444380Z",
     "iopub.status.idle": "2021-05-21T13:26:03.966124Z",
     "shell.execute_reply": "2021-05-21T13:26:03.965351Z",
     "shell.execute_reply.started": "2021-05-20T20:25:54.151809Z"
    },
    "id": "d2_H_f9V_r_E",
    "papermill": {
     "duration": 7.541898,
     "end_time": "2021-05-21T13:26:03.966316",
     "exception": false,
     "start_time": "2021-05-21T13:25:56.424418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "from transformers import AutoTokenizer, TFAutoModel, AutoConfig, TFBertModel\n",
    "import tensorflow as tf\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import math\n",
    "\n",
    "from datetime import datetime\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compatible-attack",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:26:04.004167Z",
     "iopub.status.busy": "2021-05-21T13:26:04.003615Z",
     "iopub.status.idle": "2021-05-21T13:26:04.012733Z",
     "shell.execute_reply": "2021-05-21T13:26:04.012335Z",
     "shell.execute_reply.started": "2021-05-20T20:26:01.151095Z"
    },
    "papermill": {
     "duration": 0.029603,
     "end_time": "2021-05-21T13:26:04.012839",
     "exception": false,
     "start_time": "2021-05-21T13:26:03.983236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "peaceful-ontario",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:26:04.053465Z",
     "iopub.status.busy": "2021-05-21T13:26:04.052929Z",
     "iopub.status.idle": "2021-05-21T13:26:05.140382Z",
     "shell.execute_reply": "2021-05-21T13:26:05.139868Z",
     "shell.execute_reply.started": "2021-05-20T20:26:05.373088Z"
    },
    "id": "Nq_CNQdb_trB",
    "papermill": {
     "duration": 1.112538,
     "end_time": "2021-05-21T13:26:05.140512",
     "exception": false,
     "start_time": "2021-05-21T13:26:04.027974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url_test = \"https://raw.githubusercontent.com/ipavlopoulos/toxic_spans/master/data/tsd_test.csv\"\n",
    "url_train = \"https://raw.githubusercontent.com/ipavlopoulos/toxic_spans/master/data/tsd_train.csv\"\n",
    "url_trial = \"https://raw.githubusercontent.com/ipavlopoulos/toxic_spans/master/data/tsd_trial.csv\"\n",
    "\n",
    "train_df = pd.read_csv(url_train, error_bad_lines=False)\n",
    "test_df = pd.read_csv(url_test, error_bad_lines=False)\n",
    "trial_df = pd.read_csv(url_trial, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-marathon",
   "metadata": {
    "id": "H230C3Jbf_iU",
    "papermill": {
     "duration": 0.015146,
     "end_time": "2021-05-21T13:26:05.171410",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.156264",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "specified-inspector",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:26:05.209685Z",
     "iopub.status.busy": "2021-05-21T13:26:05.209102Z",
     "iopub.status.idle": "2021-05-21T13:26:05.213027Z",
     "shell.execute_reply": "2021-05-21T13:26:05.212626Z",
     "shell.execute_reply.started": "2021-05-20T20:26:06.3146Z"
    },
    "papermill": {
     "duration": 0.025196,
     "end_time": "2021-05-21T13:26:05.213135",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.187939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "synonyms = ['calumniation', 'insult', 'swearing', 'threat', 'discrimination', \n",
    "            'toxic words', 'severe toxic words', 'poisonous words', \n",
    "            'severe poisonous words', 'hate speech', 'offensive language', \n",
    "            'hatred', 'anger', 'violence', 'abuse', 'rudeness', \n",
    "            'profanity', 'cursing', 'intimidation', 'bullying', \n",
    "            'oppression', 'menace', 'stereotype', 'sexual harassment', 'hateful words'] \n",
    "\n",
    "\n",
    "dicriminations = ['adultism', 'ageism', 'age discrimination',\n",
    "                  'caste,ableism', 'disablism', 'disability discrimination', \n",
    "                  'linguistic discrimination', 'racism', 'racial discrimination', \n",
    "                  'discrimination based on skin colour', 'ethnic discrimination', \n",
    "                  'racial segregation', 'religious bigotry', 'religious discrimination',\n",
    "                  'sexism', 'homophobia', 'misogyny', 'misandry', 'transphobia', \n",
    "                  'biphobia', 'lookism', 'antisemitism', 'hispanophobia', \n",
    "                  'islamophobia', 'sizeism', 'xenophobia', 'chauvinism', \n",
    "                  'afrophobia', 'anti-arabism', 'apostasy', 'colourism', \n",
    "                  'heightism', 'discrimination against intersex people', \n",
    "                  'supremacism', 'genetic discrimination', 'mentalism', \n",
    "                  'antisexualism', 'anti-Catholicism'] \n",
    "\n",
    "patterns = ['Does the text include toxicity, such as', \n",
    "            'Does the text include',\n",
    "            'Select spans of toxicity in the text, such as', \n",
    "            'Find spans of toxicity in the text, such as',\n",
    "            'Find in the text spans of toxicity, such as']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "expanded-spanish",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:26:05.249913Z",
     "iopub.status.busy": "2021-05-21T13:26:05.248705Z",
     "iopub.status.idle": "2021-05-21T13:26:05.251526Z",
     "shell.execute_reply": "2021-05-21T13:26:05.251071Z",
     "shell.execute_reply.started": "2021-05-20T20:26:06.323969Z"
    },
    "papermill": {
     "duration": 0.023307,
     "end_time": "2021-05-21T13:26:05.251648",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.228341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_question(number_words):\n",
    "    \n",
    "    pattern = np.random.choice(patterns, 1)[0]\n",
    "    flag = 'Does' in pattern\n",
    "    \n",
    "    toxic_words = set()\n",
    "\n",
    "    while len(toxic_words) < number_words:\n",
    "        if np.random.random() > 0.5:\n",
    "            toxic_words.add(np.random.choice(synonyms, 1)[0])\n",
    "        else:\n",
    "            toxic_words.add(np.random.choice(dicriminations, 1)[0])\n",
    "            \n",
    "    question = pattern + ' ' + ', '.join(toxic_words) + '?'* flag\n",
    "    \n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caroline-basin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:26:05.306742Z",
     "iopub.status.busy": "2021-05-21T13:26:05.295137Z",
     "iopub.status.idle": "2021-05-21T13:26:05.324325Z",
     "shell.execute_reply": "2021-05-21T13:26:05.324693Z",
     "shell.execute_reply.started": "2021-05-20T20:26:06.34198Z"
    },
    "papermill": {
     "duration": 0.057924,
     "end_time": "2021-05-21T13:26:05.324825",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.266901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SQuADTokenizedWords:\n",
    "    \n",
    "    def __init__(self, model_name, MAX_LEN, shape, decay = 0.9):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True, use_fast = False)\n",
    "        self.shape = shape\n",
    "        self.decay = decay\n",
    "        np.random.seed(SEED)\n",
    "        self.contexts, self.questions, self.answers = self.preprocessing()\n",
    "\n",
    "\n",
    "    def preprocessing(self):\n",
    "        \n",
    "        squad_dev = pd.read_json('https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json')['data'].reset_index()\n",
    "\n",
    "        contexts = []\n",
    "        questions = []\n",
    "        answers = []\n",
    "\n",
    "        imp_contexts = []\n",
    "        imp_questions = []\n",
    "        imp_answers = []\n",
    "\n",
    "        for instance in squad_dev['data']:\n",
    "            for paragraph in instance['paragraphs']:\n",
    "                context = paragraph['context']\n",
    "\n",
    "                for qas in paragraph['qas']:\n",
    "                    \n",
    "                    question = qas['question']\n",
    "                    if len(context.split()) + len(question.split()) > self.MAX_LEN * self.decay:\n",
    "                        continue \n",
    "                        \n",
    "                    if qas['is_impossible']:\n",
    "                        answer = {}\n",
    "                        imp_contexts.append(context)\n",
    "                        imp_questions.append(question)\n",
    "                        answer['ans'] = 'impossible'\n",
    "                        answer['start_ans'] = -1\n",
    "                        answer['end_ans'] = -1\n",
    "                        imp_answers.append(answer)\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    for answer in qas['answers']:\n",
    "\n",
    "                        start = answer['answer_start']\n",
    "\n",
    "                        end = len(answer['text'])\n",
    "                        contexts.append(context)\n",
    "                        questions.append(question)\n",
    "\n",
    "                        ans = {}\n",
    "                        ans['ans'] = answer['text']\n",
    "                        ans['start_ans'] = answer['answer_start']\n",
    "                        ans['end_ans'] = answer['answer_start'] + len(answer['text']) - 1\n",
    "\n",
    "                        answers.append(ans)\n",
    "                        \n",
    "        shape = self.shape // 2\n",
    "        \n",
    "        \n",
    "        indices = np.random.choice(np.arange(len(contexts)), shape)\n",
    "        contexts = np.random.choice(contexts, shape, replace = False).tolist()\n",
    "        questions = np.random.choice(questions, shape, replace = False).tolist()\n",
    "        answers = np.random.choice(answers, shape, replace = False).tolist()\n",
    "\n",
    "        \n",
    "        indices = np.random.choice(np.arange(len(imp_contexts)), shape)\n",
    "        imp_contexts = np.random.choice(imp_contexts, shape, replace = False).tolist()\n",
    "        imp_questions = np.random.choice(imp_questions, shape, replace = False).tolist()\n",
    "        imp_answers = np.random.choice(imp_answers, shape, replace = False).tolist()\n",
    "        \n",
    "        contexts +=  imp_contexts\n",
    "        questions += imp_questions\n",
    "        answers += imp_answers\n",
    "        \n",
    "        np.random.shuffle(contexts)\n",
    "        np.random.shuffle(questions)\n",
    "        np.random.shuffle(answers)   \n",
    "        \n",
    "        return contexts, questions, answers\n",
    "\n",
    "    \n",
    "    def get_params(self):\n",
    "        self.incorrect_spans = []\n",
    "        self.incorrect_indexes = []\n",
    "        all_input_ids = np.zeros((self.shape, self.MAX_LEN),dtype='int32')\n",
    "        attention_masks = np.zeros((self.shape, self.MAX_LEN),dtype='int32')\n",
    "        segment_ids = np.zeros((self.shape, self.MAX_LEN),dtype='int32')\n",
    "\n",
    "        start_positions = np.zeros((self.shape, self.MAX_LEN),dtype='int32')\n",
    "        end_positions = np.zeros((self.shape, self.MAX_LEN),dtype='int32')\n",
    "        \n",
    "        num_dropped = 0\n",
    "\n",
    "\n",
    "        for ex_num, (context, dict_answer, question) in enumerate(zip(self.contexts, self.answers, self.questions)):\n",
    "            start_char_i, end_char_i, answer = dict_answer['start_ans'], dict_answer['end_ans'],  dict_answer['ans']\n",
    "            \n",
    "            if 'roberta-base' == self.model_name or self.model_name == 'roberta-large' : \n",
    "                \n",
    "                context_toks = self.tokenizer.encode(context, add_special_tokens = False )\n",
    "                question_toks = self.tokenizer.encode(question, add_special_tokens = False)\n",
    "                \n",
    "                if answer != 'impossible':\n",
    "                    context = \" \" + \" \".join(str(context).split())\n",
    "                    answer = \" \" + \" \".join(str(answer).split())\n",
    "\n",
    "                    len_st = len(answer) - 1\n",
    "                    idx0 = None\n",
    "                    idx1 = None\n",
    "\n",
    "                    for ind in (i for i, e in enumerate(context) if e == answer[1]):\n",
    "                        if ' ' + context[ind: ind + len_st] == answer:\n",
    "                            idx0 = ind\n",
    "                            idx1 = ind + len_st - 1\n",
    "                            break\n",
    "\n",
    "                    char_targets = [0] * len(context)\n",
    "                    if idx0 != None and idx1 != None:\n",
    "                        for ct in range(idx0, idx1 + 1):\n",
    "                            char_targets[ct] = 1\n",
    "\n",
    "                \n",
    "                    offsets = []; idx=0\n",
    "                    for t in context_toks:\n",
    "                        w = self.tokenizer.decode([t])\n",
    "                        offsets.append((idx,idx+len(w)))\n",
    "                        idx += len(w)\n",
    "\n",
    "                    target_idx = []\n",
    "                    for j, (offset1, offset2) in enumerate(offsets):\n",
    "                        if sum(char_targets[offset1: offset2]) > 0:\n",
    "                            target_idx.append(j)\n",
    "\n",
    "                    targets_start = target_idx[0]\n",
    "                    targets_end = target_idx[-1]\n",
    "                    \n",
    "                    input_ids = [self.tokenizer.cls_token_id] +  question_toks + \\\n",
    "                            [self.tokenizer.sep_token_id] + [self.tokenizer.sep_token_id] \\\n",
    "                                + context_toks + [self.tokenizer.sep_token_id]\n",
    "                    token_type_ids = [0] + [0] * len(question_toks) + [0, 0] +  [0] * len(context_toks) + [0]\n",
    "                    mask = [1] * len(token_type_ids)\n",
    "                    targets_start =  targets_start + len(question_toks) + 3\n",
    "                    targets_end = targets_end + len(question_toks) + 3\n",
    "                else:\n",
    "                    input_ids = [self.tokenizer.cls_token_id] +  question_toks + \\\n",
    "                            [self.tokenizer.sep_token_id] + [self.tokenizer.sep_token_id] \\\n",
    "                                + context_toks + [self.tokenizer.sep_token_id]\n",
    "                    token_type_ids = [0] + [0] * len(question_toks) + [0, 0] +  [0] * len(context_toks) + [0]\n",
    "                    mask = [1] * len(token_type_ids)\n",
    "                    targets_start = -1\n",
    "                    targets_end = -1 \n",
    "\n",
    "                padding_length = self.MAX_LEN - len(input_ids)\n",
    "                if padding_length > 0:\n",
    "                    all_input_ids[ex_num, ] = input_ids + ([self.tokenizer.pad_token_id] * padding_length)\n",
    "                    attention_masks[ex_num, ] = mask + ([0] * padding_length)\n",
    "                    segment_ids[ex_num, ] = token_type_ids + ([0] * padding_length)\n",
    "                else:\n",
    "                    all_input_ids[ex_num, ] = input_ids[:padding_length - 1] + [self.tokenizer.pad_token_id]\n",
    "                    attention_masks[ex_num, ] = mask[:padding_length-1] + [1]\n",
    "                    segment_ids[ex_num, ] = token_type_ids[:padding_length-1] + [1]\n",
    "                    if targets_start >= self.MAX_LEN:\n",
    "                        targets_start = self.MAX_LEN - 1\n",
    "                    if targets_end >= self.MAX_LEN:\n",
    "                        targets_end = self.MAX_LEN - 1\n",
    "                    \n",
    "                start_positions[ex_num, targets_start] = 1\n",
    "                end_positions[ex_num, targets_end] = 1\n",
    "\n",
    "            else:\n",
    "                if answer != 'impossible':\n",
    "                    answer_tokens = self.tokenizer.tokenize(answer)\n",
    "                    mask_token = self.tokenizer.decode(self.tokenizer.mask_token_id).replace(' ', '')\n",
    "                    sentinel_str = ' '.join([mask_token]*len(answer_tokens))\n",
    "\n",
    "                    context_w_sentinel = context[:start_char_i] + sentinel_str + context[end_char_i:]\n",
    "\n",
    "                    encoded_dict = self.tokenizer.encode_plus(\n",
    "                                                    question, \n",
    "                                                    context_w_sentinel,\n",
    "                                                    add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
    "                                                    max_length = self.MAX_LEN,       # Pad & truncate all sentences.\n",
    "                                                    pad_to_max_length = True,\n",
    "                                                    truncation = True,\n",
    "                                                    return_attention_mask = True,\n",
    "                                                    return_token_type_ids = True)\n",
    "\n",
    "\n",
    "                    input_ids = np.array(encoded_dict['input_ids'])\n",
    "\n",
    "                    mask_token_indeces = np.where(input_ids == self.tokenizer.mask_token_id)[0]\n",
    "\n",
    "                    if not len(mask_token_indeces) == len(answer_tokens):\n",
    "                        num_dropped += 1\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    start_index = mask_token_indeces[0]\n",
    "                    end_index = mask_token_indeces[-1]\n",
    "\n",
    "                    answer_token_ids = self.tokenizer.encode(answer_tokens, add_special_tokens=False )\n",
    "\n",
    "                    input_ids[start_index : end_index + 1] = answer_token_ids\n",
    "\n",
    "                    all_input_ids[ex_num, ] = input_ids\n",
    "                    attention_masks[ex_num, ] = np.array(encoded_dict['attention_mask'])\n",
    "                    segment_ids[ex_num, ] = np.array(encoded_dict['token_type_ids'])\n",
    "\n",
    "                    start_positions[ex_num, start_index] = 1\n",
    "                    end_positions[ex_num, end_index] = 1\n",
    "                else:\n",
    "                    encoded_dict = self.tokenizer.encode_plus(\n",
    "                                                    question, \n",
    "                                                    context,\n",
    "                                                    add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
    "                                                    max_length = self.MAX_LEN,       # Pad & truncate all sentences.\n",
    "                                                    pad_to_max_length = True,\n",
    "                                                    truncation = True,\n",
    "                                                    return_attention_mask = True,\n",
    "                                                    return_token_type_ids = True)\n",
    "                    \n",
    "                    all_input_ids[ex_num, ] = np.array(encoded_dict['input_ids'])\n",
    "                    attention_masks[ex_num, ] = np.array(encoded_dict['attention_mask'])\n",
    "                    segment_ids[ex_num, ] = np.array(encoded_dict['token_type_ids'])\n",
    "                    \n",
    "                    sep_index = np.where(np.array(encoded_dict['input_ids']) == self.tokenizer.sep_token_id)[-1]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    start_index = sep_index\n",
    "                    end_index = sep_index\n",
    "\n",
    "                    start_positions[ex_num, start_index] = 1\n",
    "                    end_positions[ex_num, end_index] = 1\n",
    "        \n",
    "        print(f'The number of dropped examples: {num_dropped}')\n",
    "                    \n",
    "                \n",
    "        return all_input_ids, attention_masks, segment_ids, start_positions, end_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "threaded-raleigh",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:26:05.373421Z",
     "iopub.status.busy": "2021-05-21T13:26:05.368023Z",
     "iopub.status.idle": "2021-05-21T13:26:05.398584Z",
     "shell.execute_reply": "2021-05-21T13:26:05.398946Z",
     "shell.execute_reply.started": "2021-05-20T20:26:06.389772Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.059243,
     "end_time": "2021-05-21T13:26:05.399077",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.339834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TokenizedWords:\n",
    "    \n",
    "    def __init__(self, df, toxic_question, model_name, MAX_LEN, impossible = False, formatted = False, num_words = 10):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True, use_fast = False)\n",
    "        self.impossible = impossible\n",
    "        self.formatted = formatted\n",
    "        self.df = df\n",
    "\n",
    "        self.contexts, self.answers, self.number_of_toxic_words = self.preprocessing(df)\n",
    "            \n",
    "        self.shape = len(self.contexts)\n",
    "        \n",
    "        if toxic_question == None:\n",
    "            np.random.seed(SEED)\n",
    "            self.questions = [get_question(num_words)  for _ in range(self.shape)]\n",
    "        else:\n",
    "            self.questions = [toxic_question] * self.shape\n",
    "        \n",
    "        \n",
    "    def text_cleaning(self, text):\n",
    "        punc = (\"'\", \",\", \".\", \"?\", \"!\", '\"')\n",
    "        text = text.replace('\\n', ' ')\n",
    "        for p in punc:\n",
    "            text = text.replace(p , ' ' + p + ' ')\n",
    "\n",
    "        for space in range(2, 5):\n",
    "            text = text.replace(' '*space, ' ')\n",
    "        return text\n",
    "       \n",
    "    def preprocessing(self, df: pd.DataFrame,):\n",
    "        contexts = []\n",
    "        answers = []\n",
    "        number_of_toxic_words = []\n",
    "        num_imp = 0\n",
    "\n",
    "        for i in range(len(df)):\n",
    "        \n",
    "            text_str = df['spans'][i]\n",
    "            splitted_str = text_str[1:-1].split(\", \")\n",
    "\n",
    "            if len(splitted_str) == 1:\n",
    "                if self.impossible:\n",
    "                    #pad_token = self.tokenizer.decode(self.tokenizer.pad_token_id).replace(' ', '')\n",
    "                    contexts.append(df['text'][i])\n",
    "                    answers.append({\"start_ans\": -1, \"end_ans\": -1, 'ans': 'impossible'})\n",
    "                    num_imp += 1\n",
    "                continue\n",
    "\n",
    "            \n",
    "            splitted_str = list(map(int, splitted_str))\n",
    "\n",
    "            context = df['text'][i]\n",
    "\n",
    "            gaps = [[s, e] for s, e in zip(splitted_str, splitted_str[1:]) if s + 1 < e]\n",
    "            edges = iter(splitted_str[:1] + sum(gaps, []) + splitted_str[-1:])\n",
    "            unformatted_answers = list(zip(edges, edges))\n",
    "            \n",
    "            toxic_words = [context[tokens[0]:tokens[1] + 1] for tokens in unformatted_answers]\n",
    "            formatted_toxic_words = [self.text_cleaning(toxic_word) for toxic_word in toxic_words]\n",
    "\n",
    "            cleaned_context = self.text_cleaning(context)\n",
    "\n",
    "            indices = [(cleaned_context.index(toxic_word), cleaned_context.index(toxic_word) + len(toxic_word))\n",
    "                        for toxic_word in formatted_toxic_words]\n",
    "\n",
    "\n",
    "            for tokens, new_tokens in zip(unformatted_answers, indices):\n",
    "                start_token, end_token = tokens[0], tokens[1]\n",
    "                new_start_token, new_end_token = new_tokens[0], new_tokens[1]\n",
    "\n",
    "                answer = {}\n",
    "                if self.formatted:\n",
    "                    answer[\"start_ans\"] = new_start_token\n",
    "                    answer[\"end_ans\"] = new_end_token + 1\n",
    "                    answer['ans'] = self.text_cleaning(cleaned_context[new_start_token: new_end_token])\n",
    "                    contexts.append(cleaned_context) \n",
    "                    answers.append(answer)\n",
    "                else:\n",
    "                    answer[\"start_ans\"] = start_token\n",
    "                    answer[\"end_ans\"] = end_token + 1\n",
    "                    answer['ans'] = context[start_token:end_token+1]\n",
    "                    contexts.append(context)\n",
    "                    answers.append(answer)\n",
    "                    \n",
    "            number_of_toxic_words.append(len(unformatted_answers))\n",
    "                \n",
    "        print(f\"Number impossible: {num_imp}\")\n",
    "        return contexts, answers, number_of_toxic_words \n",
    "\n",
    "    \n",
    "    def get_params(self):\n",
    "        self.incorrect_spans = []\n",
    "        self.incorrect_indexes = []\n",
    "        all_input_ids = np.zeros((self.shape, self.MAX_LEN),dtype='int32')\n",
    "        attention_masks = np.zeros((self.shape, self.MAX_LEN),dtype='int32')\n",
    "        segment_ids = np.zeros((self.shape, self.MAX_LEN),dtype='int32')\n",
    "\n",
    "        start_positions = np.zeros((self.shape, self.MAX_LEN),dtype='int32')\n",
    "        end_positions = np.zeros((self.shape, self.MAX_LEN),dtype='int32')\n",
    "        \n",
    "        num_dropped = 0\n",
    "\n",
    "\n",
    "        for ex_num, (context, dict_answer, question) in enumerate(zip(self.contexts, self.answers, self.questions)):\n",
    "            start_char_i, end_char_i, answer = dict_answer['start_ans'], dict_answer['end_ans'],  dict_answer['ans']\n",
    "            \n",
    "            if 'roberta-base' == self.model_name or self.model_name == 'roberta-large' : \n",
    "                \n",
    "                context_toks = self.tokenizer.encode(context, add_special_tokens = False )\n",
    "                question_toks = self.tokenizer.encode(question, add_special_tokens = False)\n",
    "                \n",
    "                if answer != 'impossible':\n",
    "                    context = \" \" + \" \".join(str(context).split())\n",
    "                    answer = \" \" + \" \".join(str(answer).split())\n",
    "\n",
    "\n",
    "                    len_st = len(answer) - 1\n",
    "                    idx0 = None\n",
    "                    idx1 = None\n",
    "\n",
    "                    for ind in (i for i, e in enumerate(context) if e == answer[1]):\n",
    "                        if ' ' + context[ind: ind + len_st] == answer:\n",
    "                            idx0 = ind\n",
    "                            idx1 = ind + len_st - 1\n",
    "                            break\n",
    "\n",
    "                    char_targets = [0] * len(context)\n",
    "                    if idx0 != None and idx1 != None:\n",
    "                        for ct in range(idx0, idx1 + 1):\n",
    "                            char_targets[ct] = 1\n",
    "\n",
    "                \n",
    "                    offsets = []; idx=0\n",
    "                    for t in context_toks:\n",
    "                        w = self.tokenizer.decode([t])\n",
    "                        offsets.append((idx,idx+len(w)))\n",
    "                        idx += len(w)\n",
    "\n",
    "                    target_idx = []\n",
    "                    for j, (offset1, offset2) in enumerate(offsets):\n",
    "                        if sum(char_targets[offset1: offset2]) > 0:\n",
    "                            target_idx.append(j)\n",
    "\n",
    "                    targets_start = target_idx[0]\n",
    "                    targets_end = target_idx[-1]\n",
    "                    \n",
    "                    input_ids = [self.tokenizer.cls_token_id] +  question_toks + \\\n",
    "                            [self.tokenizer.sep_token_id] + [self.tokenizer.sep_token_id] \\\n",
    "                                + context_toks + [self.tokenizer.sep_token_id]\n",
    "                    token_type_ids = [0] + [0] * len(question_toks) + [0, 0] +  [0] * len(context_toks) + [0]\n",
    "                    mask = [1] * len(token_type_ids)\n",
    "                    targets_start =  targets_start + len(question_toks) + 3\n",
    "                    targets_end = targets_end + len(question_toks) + 3\n",
    "                else:\n",
    "                    input_ids = [self.tokenizer.cls_token_id] +  question_toks + \\\n",
    "                            [self.tokenizer.sep_token_id] + [self.tokenizer.sep_token_id] \\\n",
    "                                + context_toks + [self.tokenizer.sep_token_id]\n",
    "                    token_type_ids = [0] + [0] * len(question_toks) + [0, 0] +  [0] * len(context_toks) + [0]\n",
    "                    mask = [1] * len(token_type_ids)\n",
    "                    targets_start = -1\n",
    "                    targets_end = -1 \n",
    "                    \n",
    "                \n",
    "\n",
    "                padding_length = self.MAX_LEN - len(input_ids)\n",
    "                if padding_length > 0:\n",
    "                    all_input_ids[ex_num, ] = input_ids + ([self.tokenizer.pad_token_id] * padding_length)\n",
    "                    attention_masks[ex_num, ] = mask + ([0] * padding_length)\n",
    "                    segment_ids[ex_num, ] = token_type_ids + ([0] * padding_length)\n",
    "                else:\n",
    "                    all_input_ids[ex_num, ] = input_ids[:padding_length - 1] + [self.tokenizer.pad_token_id]\n",
    "                    attention_masks[ex_num, ] = mask[:padding_length-1] + [1]\n",
    "                    segment_ids[ex_num, ] = token_type_ids[:padding_length-1] + [1]\n",
    "                    if targets_start >= self.MAX_LEN:\n",
    "                        targets_start = self.MAX_LEN - 1\n",
    "                    if targets_end >= self.MAX_LEN:\n",
    "                        targets_end = self.MAX_LEN - 1\n",
    "                    \n",
    "                start_positions[ex_num, targets_start] = 1\n",
    "                end_positions[ex_num, targets_end] = 1\n",
    "\n",
    "            else:\n",
    "                if answer != 'impossible':\n",
    "                    answer_tokens = self.tokenizer.tokenize(answer)\n",
    "                    mask_token = self.tokenizer.decode(self.tokenizer.mask_token_id).replace(' ', '')\n",
    "                    sentinel_str = ' '.join([mask_token]*len(answer_tokens))\n",
    "\n",
    "                    context_w_sentinel = context[:start_char_i] + sentinel_str + context[end_char_i:]\n",
    "\n",
    "                    encoded_dict = self.tokenizer.encode_plus(\n",
    "                                                    question, \n",
    "                                                    context_w_sentinel,\n",
    "                                                    add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
    "                                                    max_length = self.MAX_LEN,       # Pad & truncate all sentences.\n",
    "                                                    pad_to_max_length = True,\n",
    "                                                    truncation = True,\n",
    "                                                    return_attention_mask = True,\n",
    "                                                    return_token_type_ids = True)\n",
    "\n",
    "\n",
    "                    input_ids = np.array(encoded_dict['input_ids'])\n",
    "\n",
    "                    mask_token_indeces = np.where(input_ids == self.tokenizer.mask_token_id)[0]\n",
    "\n",
    "                    if not len(mask_token_indeces) == len(answer_tokens):\n",
    "                        num_dropped += 1\n",
    "                        continue\n",
    "\n",
    "\n",
    "                    start_index = mask_token_indeces[0]\n",
    "                    end_index = mask_token_indeces[-1]\n",
    "\n",
    "                    answer_token_ids = self.tokenizer.encode(answer_tokens, add_special_tokens=False )\n",
    "\n",
    "                    input_ids[start_index : end_index + 1] = answer_token_ids\n",
    "\n",
    "                    all_input_ids[ex_num, ] = input_ids\n",
    "                    attention_masks[ex_num, ] = np.array(encoded_dict['attention_mask'])\n",
    "                    segment_ids[ex_num, ] = np.array(encoded_dict['token_type_ids'])\n",
    "\n",
    "                    start_positions[ex_num, start_index] = 1\n",
    "                    end_positions[ex_num, end_index] = 1\n",
    "                else:\n",
    "                    encoded_dict = self.tokenizer.encode_plus(\n",
    "                                                    question, \n",
    "                                                    context,\n",
    "                                                    add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
    "                                                    max_length = self.MAX_LEN,       # Pad & truncate all sentences.\n",
    "                                                    pad_to_max_length = True,\n",
    "                                                    truncation = True,\n",
    "                                                    return_attention_mask = True,\n",
    "                                                    return_token_type_ids = True)\n",
    "                    \n",
    "                    all_input_ids[ex_num, ] = np.array(encoded_dict['input_ids'])\n",
    "                    attention_masks[ex_num, ] = np.array(encoded_dict['attention_mask'])\n",
    "                    segment_ids[ex_num, ] = np.array(encoded_dict['token_type_ids'])\n",
    "                    \n",
    "                    sep_index = np.where(np.array(encoded_dict['input_ids']) == self.tokenizer.sep_token_id)[-1]\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    start_index = sep_index#-1\n",
    "                    end_index = sep_index#-1\n",
    "\n",
    "                    start_positions[ex_num, start_index] = 1\n",
    "                    end_positions[ex_num, end_index] = 1\n",
    "        \n",
    "        print(f'The number of dropped examples: {num_dropped}')\n",
    "                    \n",
    "                \n",
    "        return all_input_ids, attention_masks, segment_ids, start_positions, end_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-ideal",
   "metadata": {
    "id": "_OM50bWWEEC_",
    "papermill": {
     "duration": 0.015227,
     "end_time": "2021-05-21T13:26:05.429396",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.414169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abstract-institution",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:26:05.466709Z",
     "iopub.status.busy": "2021-05-21T13:26:05.465990Z",
     "iopub.status.idle": "2021-05-21T13:26:05.469437Z",
     "shell.execute_reply": "2021-05-21T13:26:05.469033Z",
     "shell.execute_reply.started": "2021-05-20T20:26:06.439266Z"
    },
    "papermill": {
     "duration": 0.024989,
     "end_time": "2021-05-21T13:26:05.469540",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.444551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def jaccard_score(pred, true): \n",
    "    pred_tokens = set(pred.lower().split())\n",
    "    true_tokens = set(true.lower().split())\n",
    "    if (len(pred_tokens)==0) & (len(true_tokens)==0): \n",
    "        return 0.5\n",
    "    inter_tokens = pred_tokens.intersection(true_tokens)\n",
    "    return float(len(inter_tokens)) / (len(pred_tokens) + len(true_tokens) - len(inter_tokens))\n",
    "\n",
    "\n",
    "def f1_score(pred, true):\n",
    "    pred_tokens = pred.lower().split()\n",
    "    true_tokens = true.lower().split()\n",
    "\n",
    "    if len(pred_tokens) == 0 or len(true_tokens) == 0:\n",
    "        return int(pred_tokens == true_tokens) \n",
    "\n",
    "    common_tokens = set(pred_tokens) & set(true_tokens)\n",
    "\n",
    "    if len(common_tokens) == 0:\n",
    "        return 0\n",
    "\n",
    "    prec = len(common_tokens) / len(pred_tokens)\n",
    "    rec = len(common_tokens) / len(true_tokens)\n",
    "\n",
    "    return 2 * (prec * rec) / (prec + rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "established-radio",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:26:05.534425Z",
     "iopub.status.busy": "2021-05-21T13:26:05.517903Z",
     "iopub.status.idle": "2021-05-21T13:26:05.554272Z",
     "shell.execute_reply": "2021-05-21T13:26:05.554635Z",
     "shell.execute_reply.started": "2021-05-20T20:26:06.642358Z"
    },
    "papermill": {
     "duration": 0.070201,
     "end_time": "2021-05-21T13:26:05.554777",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.484576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " class TfModel:\n",
    "        \n",
    "    def __init__(self, model_name, train_params, val_params, test_params, MAX_LEN, prefit = False):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.config = AutoConfig.from_pretrained(model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=True, use_fast = False)\n",
    "        self.MAX_LEN = MAX_LEN\n",
    "        self.prefit = prefit\n",
    "        \n",
    "        self.all_input_ids, self.attention_masks, self.segment_ids, self.start_positions, self.end_positions = train_params\n",
    "        self.all_input_ids_v, self.attention_masks_v, self.segment_ids_v, self.start_positions_v, self.end_positions_v = val_params\n",
    "        self.all_input_ids_t, self.attention_masks_t, self.segment_ids_t, self.start_positions_t, self.end_positions_t = test_params\n",
    "        \n",
    "        self.train_dataset_len = self.all_input_ids.shape[0]\n",
    "        self.valid_dataset_len = self.all_input_ids_v.shape[0]\n",
    "        self.test_dataset_len = self.all_input_ids_t.shape[0]\n",
    "        \n",
    "        self.n_steps = self.train_dataset_len // BATCH_SIZE\n",
    "        self.n_val_steps = self.valid_dataset_len // BATCH_SIZE\n",
    "        \n",
    "        #valid\n",
    "        self.oof_start = np.zeros((self.train_dataset_len, self.MAX_LEN))\n",
    "        self.oof_end = np.zeros((self.train_dataset_len, self.MAX_LEN))\n",
    "        \n",
    "        \n",
    "        #train\n",
    "        self.preds_start_train = np.zeros((self.train_dataset_len, self.MAX_LEN))\n",
    "        self.preds_end_train = np.zeros((self.train_dataset_len, self.MAX_LEN))\n",
    "        \n",
    "        #test\n",
    "        self.preds_start = np.zeros((self.test_dataset_len, self.MAX_LEN))\n",
    "        self.preds_end = np.zeros((self.test_dataset_len, self.MAX_LEN))\n",
    "              \n",
    "    \n",
    "    def save_weights(self, model, dst_fn):\n",
    "        weights = model.get_weights()\n",
    "        with open(dst_fn, 'wb') as f:\n",
    "            pickle.dump(weights, f)\n",
    "\n",
    "    def load_weights(self, model, weight_fn):\n",
    "        with open(weight_fn, 'rb') as f:\n",
    "            weights = pickle.load(f)\n",
    "        model.set_weights(weights)\n",
    "        return model\n",
    "    \n",
    "    def loss_fn(self, y_true, y_pred):\n",
    "        # adjust the targets for sequence bucketing\n",
    "        ll = tf.shape(y_pred)[1]\n",
    "        y_true = y_true[:, :ll]\n",
    "        loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=LABEL_SMOOTHING)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def build_model(self, transformer_layer):\n",
    "        ids = tf.keras.layers.Input((self.MAX_LEN,), dtype=tf.int32, name = 'input_1')\n",
    "        att = tf.keras.layers.Input((self.MAX_LEN,), dtype=tf.int32, name = 'input_2')\n",
    "        tok = tf.keras.layers.Input((self.MAX_LEN,), dtype=tf.int32, name = 'input_3')\n",
    "        padding = tf.cast(tf.equal(ids, self.tokenizer.pad_token_id), tf.int32)\n",
    "\n",
    "        lens = self.MAX_LEN - tf.reduce_sum(padding, -1)\n",
    "        max_len = tf.reduce_max(lens)\n",
    "        ids_ = ids[:, :max_len]\n",
    "        att_ = att[:, :max_len]\n",
    "        tok_ = tok[:, :max_len]\n",
    "\n",
    "        #config = AutoConfig.from_pretrained(model_name)\n",
    "        #bert_model = TFAutoModel.from_pretrained(model_name,config=config)\n",
    "        x = transformer_layer(ids_,attention_mask=att_,token_type_ids=tok_)\n",
    "\n",
    "        x1 = tf.keras.layers.Dropout(Dropout_new)(x[0])\n",
    "        x1 = tf.keras.layers.Conv1D(768, 2,padding='same')(x1)\n",
    "        x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "        x1 = tf.keras.layers.Conv1D(64, 2,padding='same')(x1)\n",
    "        x1 = tf.keras.layers.Dense(1)(x1)\n",
    "        x1 = tf.keras.layers.Flatten()(x1)\n",
    "        x1 = tf.keras.layers.Activation('softmax', name='output_1')(x1)\n",
    "\n",
    "        x2 = tf.keras.layers.Dropout(Dropout_new)(x[0]) \n",
    "        x2 = tf.keras.layers.Conv1D(768, 2,padding='same')(x2)\n",
    "        x2 = tf.keras.layers.LeakyReLU()(x2)\n",
    "        x2 = tf.keras.layers.Conv1D(64, 2, padding='same')(x2)\n",
    "        x2 = tf.keras.layers.Dense(1)(x2)\n",
    "        x2 = tf.keras.layers.Flatten()(x2)\n",
    "        x2 = tf.keras.layers.Activation('softmax', name='output_2')(x2)\n",
    "\n",
    "        model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr) \n",
    "        model.compile(loss= self.loss_fn, optimizer=optimizer)\n",
    "\n",
    "        # this is required as `model.predict` needs a fixed size!\n",
    "        x1_padded = tf.pad(x1, [[0, 0], [0, self.MAX_LEN - max_len]], constant_values=0.)\n",
    "        x2_padded = tf.pad(x2, [[0, 0], [0, self.MAX_LEN - max_len]], constant_values=0.)\n",
    "\n",
    "        padded_model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1_padded,x2_padded])\n",
    "        return model, padded_model\n",
    "    \n",
    "    \n",
    "    def get_train_dataset(self):\n",
    "        dataset = (\n",
    "                tf.data.Dataset\n",
    "                .from_tensor_slices(({\"input_1\": self.all_input_ids, \n",
    "                                      \"input_2\": self.attention_masks, \n",
    "                                      \"input_3\": self.segment_ids}, \n",
    "                                     {\"output_1\": self.start_positions, \n",
    "                                      \"output_2\": self.end_positions}))\n",
    "                .repeat()\n",
    "                .shuffle(2048)\n",
    "                .batch(BATCH_SIZE)\n",
    "                .prefetch(AUTO)\n",
    "            )\n",
    "        \n",
    "        return dataset\n",
    "    \n",
    "    def get_valid_dataset(self):\n",
    "        valid_dataset = (\n",
    "                tf.data.Dataset\n",
    "                 .from_tensor_slices(({\"input_1\": self.all_input_ids_v, \n",
    "                                      \"input_2\": self.attention_masks_v, \n",
    "                                      \"input_3\": self.segment_ids_v}, \n",
    "                                     {\"output_1\": self.start_positions_v, \n",
    "                                      \"output_2\": self.end_positions_v}))\n",
    "                .batch(BATCH_SIZE)\n",
    "                .cache()\n",
    "                .prefetch(AUTO)\n",
    "            )\n",
    "        \n",
    "        return valid_dataset\n",
    "    \n",
    "    def get_squad_dataset(self):\n",
    "        shape = self.train_dataset_len // 4\n",
    "        print('SQuAD dataset len : ', shape)\n",
    "        print(' ')\n",
    "        \n",
    "        squad_tokenizer = SQuADTokenizedWords(self.model_name, self.MAX_LEN, shape, decay = 0.9)\n",
    "        inputs, attentions, segments, starts, ends = squad_tokenizer.get_params()\n",
    "        \n",
    "        squad_dataset = (\n",
    "                tf.data.Dataset\n",
    "                .from_tensor_slices(({\"input_1\": inputs, \n",
    "                                      \"input_2\": attentions, \n",
    "                                      \"input_3\": segments}, \n",
    "                                     {\"output_1\": starts, \n",
    "                                      \"output_2\": ends}))\n",
    "                .repeat()\n",
    "                .shuffle(2048)\n",
    "                .batch(BATCH_SIZE)\n",
    "                .prefetch(AUTO)\n",
    "            )\n",
    "        \n",
    "        return squad_dataset\n",
    "        \n",
    "        \n",
    "    \n",
    "    def save_predictions(self, predictions, answers, contexts, jac_scores, f1_scores, prefix, start_idx, end_idx):\n",
    "        \n",
    "        true_answers = [ans['ans'] for ans in answers]\n",
    "        true_start = [ans['start_ans'] for ans in answers]\n",
    "        true_end = [ans['end_ans'] for ans in answers]\n",
    "        predictions_csv = pd.DataFrame({\"predictions\": predictions, \"true_answers\": true_answers, \\\n",
    "                                    'train_contexts': contexts, \"jac_scores\": jac_scores, \\\n",
    "                                    \"f1_scores\": f1_scores, 'start_pred_idx': start_idx, 'end_pred_idx': end_idx, \\\n",
    "                                    'true_start': true_start, 'true_end': true_end})\n",
    "        \n",
    "        predictions_csv.to_csv(f\"{prefix}_{self.model_name.replace('/', '_')}_predictions.csv\", index = False)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def fit(self):\n",
    "        K.clear_session()\n",
    "\n",
    "        train_dataset = self.get_train_dataset()\n",
    "        valid_dataset = self.get_valid_dataset()\n",
    "\n",
    "        with strategy.scope():\n",
    "            if self.model_name == 'SpanBERT/spanbert-base-cased' or  self.model_name == 'SpanBERT/spanbert-large-cased':\n",
    "                transformer_layer = TFBertModel.from_pretrained(self.model_name, config=self.config, from_pt = True)\n",
    "            else:\n",
    "                transformer_layer = TFAutoModel.from_pretrained(self.model_name, config=self.config)\n",
    "            model, padded_model = self.build_model(transformer_layer)\n",
    "            \n",
    "        if prefit:\n",
    "            \n",
    "            squad_dataset = self.get_squad_dataset()\n",
    "            print(\"Fit squad_data_set\", sep = '\\n')\n",
    "            \n",
    "            model.fit(\n",
    "            squad_dataset,\n",
    "            steps_per_epoch = self.n_steps // 4,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            epochs = EPOCHS, \n",
    "            shuffle = False\n",
    "        )\n",
    "            \n",
    "        print(\"Fit train_data_set\", sep = '\\n')\n",
    "\n",
    "        model.fit(\n",
    "            train_dataset,\n",
    "            steps_per_epoch = self.n_steps,\n",
    "            batch_size= BATCH_SIZE,\n",
    "            validation_data = valid_dataset,\n",
    "            epochs = EPOCHS, \n",
    "            shuffle = False\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.oof_start, self.oof_end = padded_model.predict([self.all_input_ids_v, self.attention_masks_v, \\\n",
    "                                                                 self.segment_ids_v], verbose=DISPLAY)\n",
    "        \n",
    "        val_predictions, val_jac_scores, val_f1_scores, val_st_idx, val_e_idx = self.predict(self.oof_start, self.oof_end, \\\n",
    "                                                val_contexts, val_questions, val_answers)\n",
    "        \n",
    "        self.save_predictions(val_predictions, val_answers, val_contexts, val_jac_scores, val_f1_scores, 'valid', val_st_idx, val_e_idx)\n",
    "        \n",
    "        print('>>>> VALID Jaccard =',  np.round(np.mean(val_jac_scores), 3))\n",
    "        print('>>>> VALID F1-score =',  np.round(np.mean(val_f1_scores), 3))\n",
    "        print('*****'*4)\n",
    "        \n",
    "       \n",
    "        preds_train = padded_model.predict([self.all_input_ids, self.attention_masks, self.segment_ids], verbose=DISPLAY)\n",
    "        \n",
    "        self.preds_start_train += preds_train[0]\n",
    "        self.preds_end_train += preds_train[1]\n",
    "        \n",
    "        train_predictions, train_jac_scores, train_f1_scores, tr_st_idx, tr_e_idx = self.predict(self.preds_start_train, self.preds_end_train, \\\n",
    "                                                train_contexts, train_questions, train_answers)\n",
    "        \n",
    "        self.save_predictions(train_predictions, train_answers, train_contexts, train_jac_scores, train_f1_scores, 'train', tr_st_idx, tr_e_idx)\n",
    "        \n",
    "        print('>>>> TRAIN Jaccard =', np.round(np.mean(train_jac_scores), 3))\n",
    "        print('>>>> TRAIN F1-score =',  np.round(np.mean(train_f1_scores), 3))\n",
    "        print('>>>>'*4)\n",
    "\n",
    "\n",
    "        print(\"Fit val_data_set\", sep = '\\n')\n",
    "        model.fit(\n",
    "            valid_dataset.repeat(),\n",
    "            steps_per_epoch = self.n_val_steps,\n",
    "            batch_size = BATCH_SIZE,\n",
    "            epochs = EPOCHS // 2, \n",
    "            shuffle = False\n",
    "        )\n",
    "        \n",
    "        weight_fn = f'{model_name}.h5'.replace('/', '_') #,'%s-roberta-%i.h5'%(VER,fold)\n",
    "        self.save_weights(model, weight_fn)\n",
    "\n",
    "        print('Predicting Test...')\n",
    "        preds = padded_model.predict([self.all_input_ids_t, self.attention_masks_t, self.segment_ids_t],verbose=DISPLAY)\n",
    "        self.preds_start += preds[0]\n",
    "        self.preds_end += preds[1]\n",
    "        \n",
    "        test_predictions, test_jac_scores, test_f1_scores, t_st_idx, t_e_idx = self.predict(self.preds_start, self.preds_end, \\\n",
    "                                                test_contexts, test_questions, test_answers)\n",
    "        \n",
    "        self.save_predictions(test_predictions, test_answers, test_contexts, test_jac_scores, test_f1_scores, 'test', t_st_idx, t_e_idx)\n",
    "        \n",
    "        print('>>>> TEST Jaccard =', np.round(np.mean(test_jac_scores), 3))\n",
    "        print('>>>> TEST F1-score =', np.round(np.mean(test_f1_scores), 3))\n",
    "        print('>>>>'*4)\n",
    "\n",
    "            \n",
    "    def predict(self, start, end, contexts, questions, answers):\n",
    "        idx = np.arange(len(contexts))\n",
    "        predictions, jac_scores, f1_scores, start_idx, end_idx  = [], [], [], [], []\n",
    "\n",
    "        \n",
    "        for k in idx:\n",
    "            start_pred_token = np.argmax(start[k,])\n",
    "            end_pred_token = np.argmax(end[k,]) + 1\n",
    "            \n",
    "            if start_pred_token > end_pred_token: \n",
    "                start_pred_token, end_pred_token = end_pred_token, start_pred_token\n",
    "                st = contexts[k] # IMPROVE CV/LB with better choice here\n",
    "            elif self.model_name == 'roberta-base' or self.model_name == 'roberta-large':\n",
    "                \n",
    "                context_toks = self.tokenizer.encode(contexts[k], add_special_tokens = False )\n",
    "                question_toks = self.tokenizer.encode(questions[k], add_special_tokens = False)\n",
    "                \n",
    "                input_ids = [self.tokenizer.cls_token_id] +  question_toks + \\\n",
    "                            [self.tokenizer.sep_token_id] + [self.tokenizer.sep_token_id] \\\n",
    "                                + context_toks + [self.tokenizer.sep_token_id]\n",
    "                \n",
    "                padding_length = self.MAX_LEN - len(input_ids)\n",
    "                if padding_length > 0:\n",
    "                    input_ids = input_ids + ([self.tokenizer.pad_token_id] * padding_length)\n",
    "                else:\n",
    "                    input_ids = input_ids[:padding_length - 1] + [self.tokenizer.pad_token_id]\n",
    "                    \n",
    "                st = self.tokenizer.decode(input_ids[start_pred_token:end_pred_token-1])\n",
    "            else:\n",
    "                encoded_dict = self.tokenizer.encode_plus(\n",
    "                    questions[k], \n",
    "                    contexts[k],\n",
    "                    add_special_tokens = True,  # Add '[CLS]' and '[SEP]'\n",
    "                    max_length = self.MAX_LEN,       # Pad & truncate all sentences.\n",
    "                    pad_to_max_length = True,\n",
    "                    truncation = True,\n",
    "                    return_attention_mask = True, # Construct attention masks.\n",
    "                    )\n",
    "\n",
    "                enc = np.array(encoded_dict['input_ids'])\n",
    "                st = self.tokenizer.decode(enc[start_pred_token:end_pred_token])\n",
    "\n",
    "            jaccard_sc = jaccard_score(st, answers[k]['ans'])\n",
    "            f1_sc = f1_score(st, answers[k]['ans'])\n",
    "\n",
    "            jac_scores.append(jaccard_sc)\n",
    "            f1_scores.append(f1_sc)\n",
    "            predictions.append(st)\n",
    "            start_idx.append(start_pred_token)\n",
    "            end_idx.append(end_pred_token)\n",
    "            \n",
    "        \n",
    "        return predictions, jac_scores, f1_scores, start_idx, end_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-circulation",
   "metadata": {
    "papermill": {
     "duration": 0.014838,
     "end_time": "2021-05-21T13:26:05.584915",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.570077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chinese-livestock",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:26:05.619829Z",
     "iopub.status.busy": "2021-05-21T13:26:05.619187Z",
     "iopub.status.idle": "2021-05-21T13:26:05.622021Z",
     "shell.execute_reply": "2021-05-21T13:26:05.622393Z",
     "shell.execute_reply.started": "2021-05-20T20:26:07.179626Z"
    },
    "papermill": {
     "duration": 0.022554,
     "end_time": "2021-05-21T13:26:05.622516",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.599962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DISPLAY = 2\n",
    "MAX_LEN = 256\n",
    "EPOCHS = 3 # originally 3\n",
    "BATCH_SIZE = 8 # originally 3\n",
    "SEED = 88888\n",
    "\n",
    "LABEL_SMOOTHING = 0.1\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "Dropout_new = 0.2    # originally 0.1\n",
    "n_split = 2         # originally 5\n",
    "lr = 5e-6           # originally 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "swiss-reader",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:26:05.656476Z",
     "iopub.status.busy": "2021-05-21T13:26:05.655921Z",
     "iopub.status.idle": "2021-05-21T13:26:05.659427Z",
     "shell.execute_reply": "2021-05-21T13:26:05.659817Z",
     "shell.execute_reply.started": "2021-05-20T20:26:07.511737Z"
    },
    "papermill": {
     "duration": 0.02238,
     "end_time": "2021-05-21T13:26:05.659946",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.637566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "toxic_question = None\n",
    "\n",
    "all_model_names = ['bert-base-cased', 'bert-large-cased',\n",
    "                  'roberta-base', 'roberta-large',\n",
    "                  'albert-base-v2', 'albert-large-v2', 'albert-xlarge-v2', 'albert-xxlarge-v2', \n",
    "                  \"jplu/tf-xlm-roberta-base\", \"jplu/tf-xlm-roberta-large\",\n",
    "                   'SpanBERT/spanbert-base-cased', 'SpanBERT/spanbert-large-cased']\n",
    "model_names = ['albert-xxlarge-v2',  ]#'bert-large-cased',]#\"jplu/tf-xlm-roberta-base\",]#,  \n",
    "\n",
    "\n",
    "#model_names = [  \"jplu/tf-xlm-roberta-base\", \"jplu/tf-xlm-roberta-large\" ]#[ \"jplu/tf-xlm-roberta-large\", \"jplu/tf-xlm-roberta-base\",  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "parental-birthday",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:26:05.696705Z",
     "iopub.status.busy": "2021-05-21T13:26:05.696103Z",
     "iopub.status.idle": "2021-05-21T13:26:05.702614Z",
     "shell.execute_reply": "2021-05-21T13:26:05.702181Z",
     "shell.execute_reply.started": "2021-05-20T20:26:07.997667Z"
    },
    "papermill": {
     "duration": 0.027125,
     "end_time": "2021-05-21T13:26:05.702723",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.675598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "size = len(train_df)\n",
    "np.random.seed(SEED)\n",
    "random_samples = np.random.choice(np.arange(len(train_df)), size)\n",
    "copy_df = train_df.loc[random_samples]\n",
    "copy_df.index = np.arange(size)\n",
    "\n",
    "copy_trial_df = trial_df\n",
    "copy_test_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "soviet-criticism",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T13:26:05.744021Z",
     "iopub.status.busy": "2021-05-21T13:26:05.743149Z",
     "iopub.status.idle": "2021-05-21T18:19:52.890036Z",
     "shell.execute_reply": "2021-05-21T18:19:52.889367Z",
     "shell.execute_reply.started": "2021-05-20T20:26:08.479271Z"
    },
    "papermill": {
     "duration": 17627.172627,
     "end_time": "2021-05-21T18:19:52.890233",
     "exception": false,
     "start_time": "2021-05-21T13:26:05.717606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albert-xxlarge-v2 start processing\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f424296116d1487ca768ff9f42b69765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/710 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54d6934a1b24d4793db64b695b999dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9512357ee04ed7b3575765be0714ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number impossible: 486\n",
      "The number of dropped examples: 44\n",
      "Train params processing finished\n",
      " \n",
      "Number impossible: 43\n",
      "The number of dropped examples: 2\n",
      "Valid params processing finished\n",
      " \n",
      "Number impossible: 394\n",
      "The number of dropped examples: 1\n",
      "Test params processing finished\n",
      " \n",
      "Fit process has started\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e59aa407c754b03ad687eadcca6f3ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/908M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at albert-xxlarge-v2 were not used when initializing TFAlbertModel: ['predictions']\n",
      "- This IS expected if you are initializing TFAlbertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFAlbertModel were initialized from the model checkpoint at albert-xxlarge-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFAlbertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQuAD dataset len :  2708\n",
      " \n",
      "The number of dropped examples: 0\n",
      "Fit squad_data_set\n",
      "Epoch 1/3\n",
      "902/902 [==============================] - 1351s 1s/step - loss: 13.4869 - output_1_loss: 6.7848 - output_2_loss: 6.7021\n",
      "Epoch 2/3\n",
      "902/902 [==============================] - 1327s 1s/step - loss: 168.4659 - output_1_loss: 85.1596 - output_2_loss: 83.3062\n",
      "Epoch 3/3\n",
      "902/902 [==============================] - 1323s 1s/step - loss: 620.4784 - output_1_loss: 314.5748 - output_2_loss: 305.9035\n",
      "Fit train_data_set\n",
      "Epoch 1/3\n",
      "3610/3610 [==============================] - 3758s 1s/step - loss: 206.9750 - output_1_loss: 106.3579 - output_2_loss: 100.6171 - val_loss: 210.9800 - val_output_1_loss: 108.3746 - val_output_2_loss: 102.6054\n",
      "Epoch 2/3\n",
      "3610/3610 [==============================] - 3724s 1s/step - loss: 292.3774 - output_1_loss: 149.7990 - output_2_loss: 142.5785 - val_loss: 310.5785 - val_output_1_loss: 160.0651 - val_output_2_loss: 150.5134\n",
      "Epoch 3/3\n",
      "3610/3610 [==============================] - 3760s 1s/step - loss: 373.2791 - output_1_loss: 189.9870 - output_2_loss: 183.2924 - val_loss: 402.2776 - val_output_1_loss: 206.6894 - val_output_2_loss: 195.5879\n",
      "30/30 - 133s\n",
      ">>>> VALID Jaccard = 0.587\n",
      ">>>> VALID F1-score = 0.614\n",
      "********************\n",
      "339/339 - 1534s\n",
      ">>>> TRAIN Jaccard = 0.645\n",
      ">>>> TRAIN F1-score = 0.667\n",
      ">>>>>>>>>>>>>>>>\n",
      "Fit val_data_set\n",
      "315/315 [==============================] - 292s 927ms/step - loss: 490.3084 - output_1_loss: 251.8760 - output_2_loss: 238.4323\n",
      "Predicting Test...\n",
      "71/71 - 305s\n",
      ">>>> TEST Jaccard = 0.612\n",
      ">>>> TEST F1-score = 0.631\n",
      ">>>>>>>>>>>>>>>>\n",
      "Fit process has finished\n",
      "Duration: 4:53:45.428580\n",
      "                         \n"
     ]
    }
   ],
   "source": [
    "formatted = False\n",
    "impossible = True\n",
    "prefit = True\n",
    "num_words = 10\n",
    "\n",
    "for model_name in model_names:\n",
    "    if 'large' in model_name:\n",
    "        BATCH_SIZE = 3\n",
    "        \n",
    "    start_time = datetime.now()\n",
    "    print(f\"{model_name} start processing\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    train_token = TokenizedWords(copy_df, toxic_question, model_name, MAX_LEN,  impossible = impossible, formatted = formatted, num_words = num_words)\n",
    "    all_input_ids, attention_masks, segment_ids, start_positions, end_positions = train_token.get_params()\n",
    "    train_contexts, train_questions, train_answers = train_token.contexts, train_token.questions, train_token.answers\n",
    "    \n",
    "    train_params = (all_input_ids, attention_masks, segment_ids, start_positions, end_positions)\n",
    "    print(\"Train params processing finished\")\n",
    "    print(' ')\n",
    "    \n",
    "    val_token = TokenizedWords(copy_trial_df, toxic_question, model_name, MAX_LEN,  impossible = impossible, formatted = formatted, num_words = num_words)\n",
    "    all_input_ids_v, attention_masks_v, segment_ids_v, start_positions_v, end_positions_v = val_token.get_params()\n",
    "    val_contexts, val_questions, val_answers = val_token.contexts, val_token.questions, val_token.answers\n",
    "\n",
    "    val_params = (all_input_ids_v, attention_masks_v, segment_ids_v, start_positions_v, end_positions_v)\n",
    "    print(\"Valid params processing finished\")\n",
    "    print(' ')\n",
    "    \n",
    "    test_token = TokenizedWords(copy_test_df, toxic_question, model_name, MAX_LEN,  impossible = impossible, formatted = formatted, num_words = num_words)\n",
    "    all_input_ids_t, attention_masks_t, segment_ids_t, start_positions_t, end_positions_t = test_token.get_params()\n",
    "    test_contexts, test_questions, test_answers = test_token.contexts, test_token.questions, test_token.answers\n",
    "    \n",
    "    test_params = (all_input_ids_t, attention_masks_t, segment_ids_t, start_positions_t, end_positions_t)\n",
    "    print(\"Test params processing finished\")\n",
    "    print(' ')\n",
    "\n",
    "    print(\"Fit process has started\")\n",
    "    tf_model = TfModel(model_name, train_params, val_params, test_params, MAX_LEN, prefit)\n",
    "    tf_model.fit()\n",
    "    print(\"Fit process has finished\")\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    print('Duration: {}'.format(end_time - start_time))\n",
    "    print(\" \"*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "proof-complement",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T18:20:00.038725Z",
     "iopub.status.busy": "2021-05-21T18:20:00.037641Z",
     "iopub.status.idle": "2021-05-21T18:20:00.050848Z",
     "shell.execute_reply": "2021-05-21T18:20:00.050405Z",
     "shell.execute_reply.started": "2021-05-20T22:03:07.960404Z"
    },
    "papermill": {
     "duration": 3.610941,
     "end_time": "2021-05-21T18:20:00.050970",
     "exception": false,
     "start_time": "2021-05-21T18:19:56.440029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pattern = f\"test_{model_name.replace('/', '_')}_predictions.csv\"\n",
    "predictions_csv = pd.read_csv(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "incoming-stationery",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T18:20:07.283722Z",
     "iopub.status.busy": "2021-05-21T18:20:07.283147Z",
     "iopub.status.idle": "2021-05-21T18:20:07.453662Z",
     "shell.execute_reply": "2021-05-21T18:20:07.452935Z",
     "shell.execute_reply.started": "2021-05-20T22:03:07.976709Z"
    },
    "papermill": {
     "duration": 3.682088,
     "end_time": "2021-05-21T18:20:07.453779",
     "exception": false,
     "start_time": "2021-05-21T18:20:03.771691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_csv.f1_scores.hist(figsize = (10, 6), );#.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "skilled-lewis",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T18:20:14.878604Z",
     "iopub.status.busy": "2021-05-21T18:20:14.878033Z",
     "iopub.status.idle": "2021-05-21T18:20:14.891946Z",
     "shell.execute_reply": "2021-05-21T18:20:14.892647Z"
    },
    "papermill": {
     "duration": 3.801251,
     "end_time": "2021-05-21T18:20:14.892786",
     "exception": false,
     "start_time": "2021-05-21T18:20:11.091535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>true_answers</th>\n",
       "      <th>train_contexts</th>\n",
       "      <th>jac_scores</th>\n",
       "      <th>f1_scores</th>\n",
       "      <th>start_pred_idx</th>\n",
       "      <th>end_pred_idx</th>\n",
       "      <th>true_start</th>\n",
       "      <th>true_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>jerk</td>\n",
       "      <td>jerk</td>\n",
       "      <td>Crawl in a hole and die, jerk. And before anyb...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>foolish</td>\n",
       "      <td>foolish</td>\n",
       "      <td>Wow, Lisa Ho looks foolish.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>liar</td>\n",
       "      <td>liar</td>\n",
       "      <td>Why do you think  liar, thief and evil, foul-m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>foul-mouthed</td>\n",
       "      <td>foul-mouthed</td>\n",
       "      <td>Why do you think  liar, thief and evil, foul-m...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "      <td>40</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>pathetic</td>\n",
       "      <td>pathetic</td>\n",
       "      <td>You're pathetic.  You voted for Trump because ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>up nerd</td>\n",
       "      <td>nerd</td>\n",
       "      <td>Shut up nerd. You try too hard.</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>47</td>\n",
       "      <td>49</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>dumbest</td>\n",
       "      <td>dumbest</td>\n",
       "      <td>You’re is one of the dumbest comments I’ve eve...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>sick f**ks</td>\n",
       "      <td>f**ks</td>\n",
       "      <td>Sick f**ks like this should just be shot.  Wha...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>46</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>idiot</td>\n",
       "      <td>idiot</td>\n",
       "      <td>This guy is an idiot. He was all in for shorti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>stupid</td>\n",
       "      <td>stupid</td>\n",
       "      <td>there are sick delusional people and liars, an...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>108</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>stupidity</td>\n",
       "      <td>stupidity</td>\n",
       "      <td>And you are stupidity like your Fuhrer likes t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>foolish</td>\n",
       "      <td>foolish</td>\n",
       "      <td>You cannot erase history. Why does the media g...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>71</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>cracked pot</td>\n",
       "      <td>impossible</td>\n",
       "      <td>Some of us remember your cracked pot posts abo...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46</td>\n",
       "      <td>48</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>stupidest</td>\n",
       "      <td>stupidity</td>\n",
       "      <td>I cannot fathom the stupidity of McCain believ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>121</td>\n",
       "      <td>123</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>idiots</td>\n",
       "      <td>idiots</td>\n",
       "      <td>Our country is now literally being run by Russ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67</td>\n",
       "      <td>69</td>\n",
       "      <td>115</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>crap</td>\n",
       "      <td>crap</td>\n",
       "      <td>McConnell &amp; trump’s puppy,  Our very own senat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>73</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>screwed</td>\n",
       "      <td>screwed</td>\n",
       "      <td>McConnell &amp; trump’s puppy,  Our very own senat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>idiot</td>\n",
       "      <td>idiot</td>\n",
       "      <td>\"Is this Trump ( idiot ) going to go around bu...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>thug</td>\n",
       "      <td>stupid</td>\n",
       "      <td>Round up the thug protesters and tossem in her...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>105</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>stupid</td>\n",
       "      <td>stupid</td>\n",
       "      <td>\"Look, the average Democrat voter is just plai...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predictions  true_answers  \\\n",
       "150          jerk          jerk   \n",
       "151       foolish       foolish   \n",
       "152          liar          liar   \n",
       "153  foul-mouthed  foul-mouthed   \n",
       "154      pathetic      pathetic   \n",
       "155       up nerd          nerd   \n",
       "156       dumbest       dumbest   \n",
       "157    sick f**ks         f**ks   \n",
       "158         idiot         idiot   \n",
       "159        stupid        stupid   \n",
       "160     stupidity     stupidity   \n",
       "161       foolish       foolish   \n",
       "162   cracked pot    impossible   \n",
       "163     stupidest     stupidity   \n",
       "164        idiots        idiots   \n",
       "165          crap          crap   \n",
       "166       screwed       screwed   \n",
       "167         idiot         idiot   \n",
       "168          thug        stupid   \n",
       "169        stupid        stupid   \n",
       "\n",
       "                                        train_contexts  jac_scores  f1_scores  \\\n",
       "150  Crawl in a hole and die, jerk. And before anyb...         1.0   1.000000   \n",
       "151                        Wow, Lisa Ho looks foolish.         1.0   1.000000   \n",
       "152  Why do you think  liar, thief and evil, foul-m...         1.0   1.000000   \n",
       "153  Why do you think  liar, thief and evil, foul-m...         1.0   1.000000   \n",
       "154  You're pathetic.  You voted for Trump because ...         1.0   1.000000   \n",
       "155                    Shut up nerd. You try too hard.         0.5   0.666667   \n",
       "156  You’re is one of the dumbest comments I’ve eve...         1.0   1.000000   \n",
       "157  Sick f**ks like this should just be shot.  Wha...         0.5   0.666667   \n",
       "158  This guy is an idiot. He was all in for shorti...         1.0   1.000000   \n",
       "159  there are sick delusional people and liars, an...         1.0   1.000000   \n",
       "160  And you are stupidity like your Fuhrer likes t...         1.0   1.000000   \n",
       "161  You cannot erase history. Why does the media g...         1.0   1.000000   \n",
       "162  Some of us remember your cracked pot posts abo...         0.0   0.000000   \n",
       "163  I cannot fathom the stupidity of McCain believ...         0.0   0.000000   \n",
       "164  Our country is now literally being run by Russ...         1.0   1.000000   \n",
       "165  McConnell & trump’s puppy,  Our very own senat...         1.0   1.000000   \n",
       "166  McConnell & trump’s puppy,  Our very own senat...         1.0   1.000000   \n",
       "167  \"Is this Trump ( idiot ) going to go around bu...         1.0   1.000000   \n",
       "168  Round up the thug protesters and tossem in her...         0.0   0.000000   \n",
       "169  \"Look, the average Democrat voter is just plai...         1.0   1.000000   \n",
       "\n",
       "     start_pred_idx  end_pred_idx  true_start  true_end  \n",
       "150              46            47          25        29  \n",
       "151              45            46          19        26  \n",
       "152              42            43          18        22  \n",
       "153              47            50          40        52  \n",
       "154              46            47           7        15  \n",
       "155              47            49           8        12  \n",
       "156              60            62          21        28  \n",
       "157              46            50           5        10  \n",
       "158              37            38          15        20  \n",
       "159              62            63         108       114  \n",
       "160              44            46          12        21  \n",
       "161              52            53          71        78  \n",
       "162              46            48          -1        -1  \n",
       "163             121           123          20        29  \n",
       "164              67            69         115       121  \n",
       "165              58            59          73        77  \n",
       "166              64            65          95       102  \n",
       "167              53            54          17        22  \n",
       "168              42            43         105       111  \n",
       "169              51            52          48        54  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_csv[150:170]#.f1_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abandoned-reservation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-21T18:20:22.138210Z",
     "iopub.status.busy": "2021-05-21T18:20:22.136714Z",
     "iopub.status.idle": "2021-05-21T18:20:22.138921Z",
     "shell.execute_reply": "2021-05-21T18:20:22.139376Z"
    },
    "papermill": {
     "duration": 3.672527,
     "end_time": "2021-05-21T18:20:22.139512",
     "exception": false,
     "start_time": "2021-05-21T18:20:18.466985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ЧТО можно сделать еще: показать распределение токсичных слов в каждом тексте. \n",
    "# Сколько текстов не используется при обучении с impossible questions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17679.835512,
   "end_time": "2021-05-21T18:20:29.705178",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-05-21T13:25:49.869666",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "012806f610cb4c1db23525a0efceaff2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_762a4d8533374aa280f5591f644c551b",
       "placeholder": "​",
       "style": "IPY_MODEL_f956bebdacf64f6491710aaabf032bce",
       "value": " 908M/908M [00:39&lt;00:00, 23.7MB/s]"
      }
     },
     "016db20416404773a0f55d4b12abb65c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "08b54381990542aab1ed15eea57a9d52": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0fa66f6a017c4c548f21d4867733c332": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1a4fc5db35f74f87bc1ffda465ca635d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b23e13a0088467ead5e7d6fc283af26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_561ffd9cf1dc400ca23175ecee386758",
       "max": 710.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3816dd656e8d4586a012ec2712f1aa0a",
       "value": 710.0
      }
     },
     "1d4b4e2b895f4cd78b00758a2f0f104e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "26906638e60f4afe8b94468f707e16de": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2a97a7fd1ba54711810169cb21cdd7b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "331eb98869444fb4911d14f5aef5c30d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3816dd656e8d4586a012ec2712f1aa0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "38b76ff2dc1a4aacaf0f8480b5dd9a08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3cab19da6861400dbd3f8d8b306bd927": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3e1b89d6f68e4855b041b7cec3d4b53b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3fa210bf11be414894b76e319a7bba0f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4ee2ed0c99de4ba8a456bfc6ebe3d0a7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_016db20416404773a0f55d4b12abb65c",
       "placeholder": "​",
       "style": "IPY_MODEL_b4b18ced4ed44b63b223607ea6548ff6",
       "value": " 760k/760k [00:00&lt;00:00, 883kB/s]"
      }
     },
     "504fd495111047ae85eae87eb506f0c0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5510bbbeae9f42b4bfc711dee87173ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "561ffd9cf1dc400ca23175ecee386758": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e59aa407c754b03ad687eadcca6f3ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_78edb3860ec44abcb7dc84ef46d4bebd",
        "IPY_MODEL_71f35c1045c047ea8e28ecdbda0d8259",
        "IPY_MODEL_012806f610cb4c1db23525a0efceaff2"
       ],
       "layout": "IPY_MODEL_26906638e60f4afe8b94468f707e16de"
      }
     },
     "60cc7f90465b4950b07eff2196589110": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "627b7fa62bb2487b805491ff4c472c48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_08b54381990542aab1ed15eea57a9d52",
       "placeholder": "​",
       "style": "IPY_MODEL_a953965e73d64cdba482911b149bbbe2",
       "value": " 710/710 [00:00&lt;00:00, 25.5kB/s]"
      }
     },
     "6e47cc8d5d414f54a696c604a85c4a72": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "71f35c1045c047ea8e28ecdbda0d8259": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b3b5923f01be48b99bd2e3f62090639a",
       "max": 908400376.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5510bbbeae9f42b4bfc711dee87173ed",
       "value": 908400376.0
      }
     },
     "762a4d8533374aa280f5591f644c551b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "78edb3860ec44abcb7dc84ef46d4bebd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3e1b89d6f68e4855b041b7cec3d4b53b",
       "placeholder": "​",
       "style": "IPY_MODEL_2a97a7fd1ba54711810169cb21cdd7b7",
       "value": "Downloading: 100%"
      }
     },
     "7f785d666d974f2d919b34026c6b9aa3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_504fd495111047ae85eae87eb506f0c0",
       "placeholder": "​",
       "style": "IPY_MODEL_a3a4bda6e0f4414da99c52bb098c4302",
       "value": "Downloading: 100%"
      }
     },
     "8c86b39ed15848338d844b3eed1181b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dc149981880d4930bc45ac2e4fbef690",
       "placeholder": "​",
       "style": "IPY_MODEL_38b76ff2dc1a4aacaf0f8480b5dd9a08",
       "value": " 1.31M/1.31M [00:00&lt;00:00, 2.90MB/s]"
      }
     },
     "8f8e42d420764461a029a983c03fcbbc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_994c09d1d3eb42e785d56b19c07b4179",
       "placeholder": "​",
       "style": "IPY_MODEL_1d4b4e2b895f4cd78b00758a2f0f104e",
       "value": "Downloading: 100%"
      }
     },
     "9448c490b6fd443e9ccd0d6a13d83daa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_60cc7f90465b4950b07eff2196589110",
       "placeholder": "​",
       "style": "IPY_MODEL_3cab19da6861400dbd3f8d8b306bd927",
       "value": "Downloading: 100%"
      }
     },
     "994c09d1d3eb42e785d56b19c07b4179": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a3a4bda6e0f4414da99c52bb098c4302": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a953965e73d64cdba482911b149bbbe2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b3b5923f01be48b99bd2e3f62090639a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4b18ced4ed44b63b223607ea6548ff6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c6bbf89fdbf9418982a2b3b847a424b3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1a4fc5db35f74f87bc1ffda465ca635d",
       "max": 1312669.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_331eb98869444fb4911d14f5aef5c30d",
       "value": 1312669.0
      }
     },
     "d34a08e7b46448dab12171cfd670352e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d54d6934a1b24d4793db64b695b999dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7f785d666d974f2d919b34026c6b9aa3",
        "IPY_MODEL_e8fdb308014c439a8ca959da69968f88",
        "IPY_MODEL_4ee2ed0c99de4ba8a456bfc6ebe3d0a7"
       ],
       "layout": "IPY_MODEL_0fa66f6a017c4c548f21d4867733c332"
      }
     },
     "dc149981880d4930bc45ac2e4fbef690": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e353a0b8d5204cd2b10b642c0ef64c4d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e8fdb308014c439a8ca959da69968f88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6e47cc8d5d414f54a696c604a85c4a72",
       "max": 760289.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d34a08e7b46448dab12171cfd670352e",
       "value": 760289.0
      }
     },
     "f424296116d1487ca768ff9f42b69765": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8f8e42d420764461a029a983c03fcbbc",
        "IPY_MODEL_1b23e13a0088467ead5e7d6fc283af26",
        "IPY_MODEL_627b7fa62bb2487b805491ff4c472c48"
       ],
       "layout": "IPY_MODEL_3fa210bf11be414894b76e319a7bba0f"
      }
     },
     "f956bebdacf64f6491710aaabf032bce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fd9512357ee04ed7b3575765be0714ee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9448c490b6fd443e9ccd0d6a13d83daa",
        "IPY_MODEL_c6bbf89fdbf9418982a2b3b847a424b3",
        "IPY_MODEL_8c86b39ed15848338d844b3eed1181b9"
       ],
       "layout": "IPY_MODEL_e353a0b8d5204cd2b10b642c0ef64c4d"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
